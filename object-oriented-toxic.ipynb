{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from scipy.sparse import hstack\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "import gc\n",
    "from sklearn.linear_model import Ridge\n",
    "import pickle\n",
    "import xgboost as xgb\n",
    "from xgboost.sklearn import XGBClassifier # <3\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "from sklearn.linear_model.stochastic_gradient import SGDClassifier\n",
    "import re, string\n",
    "from sklearn.ensemble import RandomForestClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/train.csv').fillna(' ')\n",
    "test = pd.read_csv('../input/test.csv').fillna(' ')\n",
    "subm = pd.read_csv('../input/sample_submission.csv')\n",
    "train_text = train['comment_text']\n",
    "test_text = test['comment_text']\n",
    "all_text = pd.concat([train_text, test_text])\n",
    "class_names = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "1ee30cc1132b2f3bba4b63ecae839215a14be01f"
   },
   "outputs": [],
   "source": [
    "class Preprocess():\n",
    "\n",
    "    def __init__(self):\n",
    "        print(\"Preprocess object created\")\n",
    "        \n",
    "    def _feature_engineering(self,all_text):\n",
    "            print(\"Inside word vectorizer\")\n",
    "            word_vectorizer = TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            strip_accents='unicode',\n",
    "            analyzer='word',\n",
    "            token_pattern=r'\\w{1,}',\n",
    "            stop_words='english',\n",
    "            ngram_range=(1, 2),min_df=2,max_df=0.5,\n",
    "            max_features=60000\n",
    "            )\n",
    "            word_vectorizer.fit(all_text)\n",
    "            train_word_features = word_vectorizer.transform(train_text)\n",
    "            test_word_features = word_vectorizer.transform(test_text)\n",
    "            char_vectorizer = TfidfVectorizer(\n",
    "            sublinear_tf=True,\n",
    "            strip_accents='unicode',\n",
    "            analyzer='char',\n",
    "            stop_words='english',\n",
    "            ngram_range=(2, 6),min_df=2,max_df=0.5,\n",
    "            max_features=60000\n",
    "            )\n",
    "            char_vectorizer.fit(all_text)\n",
    "            train_char_features = char_vectorizer.transform(train_text)\n",
    "            test_char_features = char_vectorizer.transform(test_text)\n",
    "            train_features = hstack([train_char_features,train_word_features])\n",
    "            test_features = hstack([test_char_features,test_word_features])\n",
    "            print(\"Exiting word vectorizer\")\n",
    "            return train_features,test_features\n",
    "    \n",
    "   \n",
    "           \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "6c60708198d3f6d5e084c824918eaceabdbe4bb8"
   },
   "outputs": [],
   "source": [
    "class Models():\n",
    "    def __init__(self):\n",
    "        print(\"Model Created\")\n",
    "\n",
    "    def logistic(self,train_features,test_features):\n",
    "       print(\"in logistic\")\n",
    "       self.train_features=train_features\n",
    "       self.test_features=test_features\n",
    "       scores = []\n",
    "       submission = pd.DataFrame.from_dict({'id': test['Id']})\n",
    "       for class_name in class_names:\n",
    "            train_target = train[class_name]\n",
    "            classifier = LogisticRegression(C=1, solver='sag')\n",
    "\n",
    "            cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "            scores.append(cv_score)\n",
    "            print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "            classifier.fit(train_features, train_target)\n",
    "            filename = 'logistic_model.sav'\n",
    "            pickle.dump(classifier, open(filename, 'wb'))\n",
    "            submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "       print('Total CV score is {}'.format(np.mean(scores)))\n",
    "       submission.to_csv('logistic.csv', index=False)\n",
    "    def SGD(self,train_features,test_features):\n",
    "       print(\"in SGD\")\n",
    "       self.train_features=train_features\n",
    "       self.test_features=test_features\n",
    "       scores = []\n",
    "       submission = pd.DataFrame.from_dict({'id': test['Id']})\n",
    "       for class_name in class_names:\n",
    "            train_target = train[class_name]\n",
    "            classifier = SGDClassifier(loss='modified_huber', penalty='l2', alpha=0.001, random_state=42, max_iter=200, tol=0.20, learning_rate='optimal')\n",
    "\n",
    "            cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "            scores.append(cv_score)\n",
    "            print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "            classifier.fit(train_features, train_target)\n",
    "            filename = 'SGD_model.sav'\n",
    "            pickle.dump(classifier, open(filename, 'wb'))\n",
    "            submission[class_name] = classifier.predict_proba(test_features)[:, 1]\n",
    "\n",
    "       print('Total CV score is {}'.format(np.mean(scores)))\n",
    "       submission.to_csv('SGD.csv', index=False)\n",
    "        \n",
    "    def ridge(self,train_features,test_features):\n",
    "       print(\"in ridge\")\n",
    "       self.train_features=train_features\n",
    "       self.test_features=test_features\n",
    "       scores = []\n",
    "       submission = pd.DataFrame.from_dict({'id': test['Id']})\n",
    "       for class_name in class_names:\n",
    "            train_target = train[class_name]\n",
    "            classifier = Ridge(alpha=29, copy_X=True, fit_intercept=True, solver='sag',\n",
    "                     max_iter=150,   normalize=False, random_state=0,  tol=0.0025)\n",
    "            cv_score = np.mean(cross_val_score(classifier, train_features, train_target, cv=3, scoring='roc_auc'))\n",
    "            scores.append(cv_score)\n",
    "            print('CV score for class {} is {}'.format(class_name, cv_score))\n",
    "\n",
    "            classifier.fit(train_features, train_target)\n",
    "            # save the model to disk\n",
    "            filename = 'ridge_model.sav'\n",
    "            pickle.dump(classifier, open(filename, 'wb'))\n",
    "            submission[class_name] = classifier.predict(test_features)\n",
    "\n",
    "       print('Total CV score is {}'.format(np.mean(scores)))\n",
    "       submission.to_csv('ridge.csv', index=False)\n",
    "    \n",
    "    def xgb(self,train_features,test_features):\n",
    "           print(\"in xgb\")\n",
    "           cv_scores = []\n",
    "           xgb_preds = []\n",
    "           submission = pd.DataFrame.from_dict({'id': test['Id']})\n",
    "           self.train_features=train_features\n",
    "           self.test_features=test_features\n",
    "           d_test = xgb.DMatrix(test_features)\n",
    "\n",
    "           for class_name in class_names:\n",
    "                train_target = train[class_name]\n",
    "    # Split out a validation set\n",
    "                X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "                    train_features, train_target, test_size=0.25, random_state=23)\n",
    "\n",
    "                xgb_params = {'eta': 0.3, \n",
    "                  'max_depth': 5, \n",
    "                  'subsample': 0.8, \n",
    "                  'colsample_bytree': 0.8, \n",
    "                  'objective': 'binary:logistic', \n",
    "                  'eval_metric': 'auc', \n",
    "                  'seed': 23\n",
    "                 }\n",
    "\n",
    "               # trn_lgbset = lgb.Dataset(csr_trn, free_raw_data=False)\n",
    "                d_train = xgb.DMatrix(X_train, y_train)\n",
    "                d_valid = xgb.DMatrix(X_valid, y_valid)\n",
    "                watchlist = [(d_valid, 'valid')]\n",
    "              #  model = xgb.train(xgb_params, d_train, 200, watchlist, verbose_eval=False, early_stopping_rounds=30)\n",
    "                model = xgb.train(xgb_params, d_train, 200, watchlist, verbose_eval=False, early_stopping_rounds=30)\n",
    "                filename = 'xgb_model.sav'\n",
    "                pickle.dump(model, open(filename, 'wb'))\n",
    "                print(\"class Name: {}\".format(class_name))\n",
    "                #print(model.attributes()['best_msg'])\n",
    "                cv_scores.append(float(model.attributes()['best_score']))\n",
    "                submission[class_name] = model.predict(d_test)\n",
    "                del X_train, X_valid, y_train, y_valid\n",
    "                gc.collect()\n",
    "           print('Total CV score is {}'.format(np.mean(cv_scores)))\n",
    "           submission.to_csv('xgb.csv', index=False)\n",
    "\n",
    "    def randomforest(self,train_features,test_features):\n",
    "       label_cols = ['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']\n",
    "       print(\"in random forest\")\n",
    "       re_tok = re.compile(f'([{string.punctuation}“”¨«»®´·º½¾¿¡§£₤‘’])')\n",
    "       def tokenize(s): return re_tok.sub(r' \\1 ', s).split()\n",
    "\n",
    "       n = train.shape[0]\n",
    "       vec = TfidfVectorizer(ngram_range=(1,2), tokenizer=tokenize,\n",
    "               min_df=3, max_df=0.9, strip_accents='unicode', use_idf=1,\n",
    "               smooth_idf=1, sublinear_tf=1 )\n",
    "       train_term_doc = vec.fit_transform(train['comment_text'])\n",
    "       test_term_doc = vec.transform(test['comment_text'])\n",
    "       preds = np.zeros((len(test), len(label_cols))) # empty np matrix to put in predictions\n",
    "\n",
    "       for i, j in enumerate(label_cols):\n",
    "         print('fit', j)\n",
    "         m = RandomForestClassifier(n_estimators=1000, max_leaf_nodes=18, random_state=21)\n",
    "         m.fit(train_term_doc, train[j].values)\n",
    "         filename = 'randomforest_model.sav'\n",
    "         pickle.dump(m, open(filename, 'wb'))\n",
    "         preds[:,i] = m.predict_proba(test_term_doc)[:,1]\n",
    "       submid = pd.DataFrame({'id': subm[\"Id\"]})\n",
    "       submission = pd.concat([submid, pd.DataFrame(preds, columns = label_cols)], axis=1)\n",
    "       submission.to_csv('random_forest.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "173b864292d59368170fbb82861566f0208a9860"
   },
   "outputs": [],
   "source": [
    "class Toxic():\n",
    "\n",
    "    def __init__(self, all_text):\n",
    "      \n",
    "        #Create instance of objects\n",
    "        print(\"Toxic object created\")\n",
    "        self.preprocess=Preprocess()\n",
    "        self.models=Models()\n",
    "        self.all_text=all_text\n",
    "        \n",
    "        \n",
    "        \n",
    "    def preprocessing(self, all_text):\n",
    "            \n",
    "            self.preprocess._feature_engineering(self.all_text)\n",
    "            \n",
    "    def machine_learning(self):\n",
    "           self.train_features=self.preprocess._feature_engineering_word(self.all_text)\n",
    "           self.test_features=self.preprocess._feature_engineering_char(self.all_text)\n",
    "           \n",
    "           self.models.randomforest(self.train_features,self.test_features)\n",
    "           self.models.ridge(self.train_features,self.test_features)\n",
    "           self.models.logistic(self.train_features,self.test_features)\n",
    "           self.models.SGD(self.train_features,self.test_features)\n",
    "           self.models.xgb(self.train_features,self.test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "67c3f4d4e3822fa55832e190d6c9f3f82c00a393"
   },
   "outputs": [],
   "source": [
    "Toxic=Toxic(all_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "a63db63f032bae4d70836d58a1664d8724a70eea"
   },
   "outputs": [],
   "source": [
    "Toxic.machine_learning()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_uuid": "25c8fad8ff4748b28938003eabe75dc8953d7cbf"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
